{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Graph(BaseModel):\n",
    "    region: str\n",
    "    subject: str\n",
    "    year: int\n",
    "    content: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "from selenium.common.exceptions import NoSuchWindowException\n",
    "\n",
    "class VnaNetScoreCrawler:\n",
    "    def __init__(self, data_path=int):\n",
    "        self.options = webdriver.ChromeOptions()\n",
    "        self.options.add_argument(\"--window-size=1280,720\")\n",
    "        self.url = \"https://diemthi.vnanet.vn/\"\n",
    "        self.driver = webdriver.Chrome(options=self.options)\n",
    "        self.data_path = data_path\n",
    "\n",
    "    def crawl_graph(self):\n",
    "\n",
    "        self.driver.get(self.url)\n",
    "\n",
    "        graphs = self.driver.find_elements(By.TAG_NAME, 'svg')\n",
    "        graph_data = []\n",
    "\n",
    "        # Extract data from each graph found\n",
    "        for graph in graphs:\n",
    "            score_dict = {}\n",
    "            graph_element = graph.get_attribute('outerHTML')\n",
    "            soup = BeautifulSoup(graph_element, 'html.parser')\n",
    "            g = soup.find_all('g', transform=True)\n",
    "            #graph_label = soup.find(lambda tag: tag.name == \"text\" and \"phổ điểm\" in tag.text.lower()).text\n",
    "            labels = []\n",
    "            values = []\n",
    "            for i in g:\n",
    "                # Get x axis labels\n",
    "                if len(i.findChildren()) == 1:\n",
    "                    labels.append(i.text)\n",
    "                \n",
    "                if len(i.findChildren()) == 2:\n",
    "                    values.append(i.text)\n",
    "\n",
    "            for i, j in zip(labels, values):\n",
    "                score_dict[i] = j\n",
    "\n",
    "            graph_data.append(score_dict)\n",
    "        \n",
    "        return graph_data\n",
    "    \n",
    "    def crawl_score_distribution(self):\n",
    "        self.driver.get(self.url)\n",
    "\n",
    "        region_select = self.driver.find_element(By.ID, 'listCity')\n",
    "\n",
    "        for option in region_select.find_elements(By.TAG_NAME, 'option'):\n",
    "            current_region = option.text\n",
    "            option.click()\n",
    "            print(current_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toàn quốc\n",
      "01 Sở GDĐT Hà Nội\n",
      "02 Sở GDĐT TP. Hồ Chí Minh\n",
      "03 Sở GDĐT Hải Phòng\n",
      "04 Sở GDĐT Đà Nẵng\n",
      "05 Sở GDĐT Hà Giang\n",
      "06 Sở GDĐT Cao Bằng\n",
      "07 Sở GDĐT Lai Châu\n",
      "08 Sở GDĐT Lào Cai\n",
      "09 Sở GDĐT Tuyên Quang\n",
      "10 Sở GDĐT Lạng Sơn\n",
      "11 Sở GDĐT Bắc Kạn\n",
      "12 Sở GDĐT Thái Nguyên\n",
      "13 Sở GDĐT Yên Bái\n",
      "14 Sở GDĐT Sơn La\n",
      "15 Sở GDĐT Phú Thọ\n",
      "16 Sở GDĐT Vĩnh Phúc\n",
      "17 Sở GDĐT Quảng Ninh\n",
      "18 Sở GDĐT Bắc Giang\n",
      "19 Sở GDĐT Bắc Ninh\n",
      "21 Sở GDĐT Hải Dương\n",
      "22 Sở GDĐT Hưng Yên\n",
      "23 Sở GDĐT Hoà Bình\n",
      "24 Sở GDĐT Hà Nam\n",
      "25 Sở GDĐT Nam Định\n",
      "26 Sở GDĐT Thái Bình\n",
      "27 Sở GDĐT Ninh Bình\n",
      "28 Sở GDĐT Thanh Hoá\n",
      "29 Sở GDĐT Nghệ An\n",
      "30 Sở GDĐT Hà Tĩnh\n",
      "31 Sở GDĐT Quảng Bình\n",
      "32 Sở GDĐT Quảng Trị\n",
      "33 Sở GDĐT Thừa Thiên -Huế\n",
      "34 Sở GDĐT Quảng Nam\n",
      "35 Sở GDĐT Quảng Ngãi\n",
      "36 Sở GDĐT Kon Tum\n",
      "37 Sở GDĐT Bình Định\n",
      "38 Sở GDĐT Gia Lai\n",
      "39 Sở GDĐT Phú Yên\n",
      "40 Sở GDĐT Đắk Lắk\n",
      "41 Sở GDĐT Khánh Hoà\n",
      "42 Sở GDĐT Lâm Đồng\n",
      "43 Sở GDĐT Bình Phước\n",
      "44 Sở GDĐT Bình Dương\n",
      "45 Sở GDĐT Ninh Thuận\n",
      "46 Sở GDĐT Tây Ninh\n",
      "47 Sở GDĐT Bình Thuận\n",
      "48 Sở GDĐT Đồng Nai\n",
      "49 Sở GDĐT Long An\n",
      "50 Sở GDĐT Đồng Tháp\n",
      "51 Sở GDĐT An Giang\n",
      "52 Sở GDĐT Bà Rịa-Vũng Tàu\n",
      "53 Sở GDĐT Tiền Giang\n",
      "54 Sở GDĐT Kiên Giang\n",
      "55 Sở GDĐT Cần Thơ\n",
      "56 Sở GDĐT Bến Tre\n",
      "57 Sở GDĐT Vĩnh Long\n",
      "58 Sở GDĐT Trà Vinh\n",
      "59 Sở GDĐT Sóc Trăng\n",
      "60 Sở GD KHCN Bạc Liêu\n",
      "61 Sở GDĐT Cà Mau\n",
      "62 Sở GDĐT Điện Biên\n",
      "63 Sở GDĐT Đăk Nông\n",
      "64 Sở GDĐT Hậu Giang\n",
      "65 Cục Nhà trường - Bộ Quốc phòng\n"
     ]
    }
   ],
   "source": [
    "crawler = VnaNetScoreCrawler()\n",
    "crawler.crawl_score_distribution()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
